{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#importing beautiful soap for scrapping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "`BBeautifulSoup` :    pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools #to create efficent looping to fetch more data in a go\n",
    "import re \n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating BS4 Functions for scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=1980-01-01,2021-12-31&num_votes=20000,&count=200\"\n",
    "\n",
    "#https://www.imdb.com/search/title/?title_type=feature&release_date=2020-01-01,2021-12-31&num_votes=20000,&count=200 - 1000 Files done .. processing time 45 min can be used for unlablled\n",
    "#movie released b/w 2021 and 2020 having votes more than 20k @sanjay \n",
    "\n",
    "\n",
    "#Fetching only 600 movie listing as the processing time is great. once we are good with code we can change the above filter.\n",
    "def getSoup(url):\n",
    "    \"\"\"\n",
    "    Utility function this get soup function will fetch the above url which stored in url var.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def getReviews(soup):\n",
    "    '''Function returns all reviews including postive and negative..'''\n",
    "    \n",
    "    # get a list of user ratings\n",
    "    user_review_ratings = [tag.previous_element for tag in \n",
    "                           soup.find_all('span', attrs={'class': 'point-scale'})]        #can search div by inspect elementor\n",
    "    \n",
    "    \n",
    "    # get the review tags\n",
    "    user_review_list = soup.find_all('a', attrs={'class':'title'})\n",
    "    ans = []\n",
    "    for i in range(5):\n",
    "        ans.append(user_review_list[random.randint(0, len(user_review_list) -1)])\n",
    "    links = [\"https://www.imdb.com\" + tag['href'] for tag in ans]\n",
    "    return links\n",
    "\n",
    "\n",
    "def getReviewText(review_url):\n",
    "    '''Returns the user review text given the review url.'''\n",
    "    # get the review_url's soup\n",
    "    soup = getSoup(review_url)\n",
    "    # find div tags with class text show-more__control\n",
    "    tag = soup.find('div', attrs={'class': 'text show-more__control'})\n",
    "    return tag.getText()\n",
    "\n",
    "def getMovieTitle(review_url):\n",
    "    '''Returns the movie title from the review url.'''\n",
    "    # get the review_url's soup\n",
    "    soup = getSoup(review_url)\n",
    "    # find h1 tag\n",
    "    tag = soup.find('h1')\n",
    "    return list(tag.children)[1].getText()\n",
    "\n",
    "def getNounChunks(user_review):\n",
    "    # create the doc object\n",
    "    doc = nlp(user_review)\n",
    "    # get a list of noun_chunks\n",
    "    noun_chunks = list(doc.noun_chunks)\n",
    "    # convert noun_chunks from span objects to strings, otherwise it won't pickle\n",
    "    noun_chunks_strlist = [chunk.text for chunk in noun_chunks]\n",
    "    return noun_chunks_strlist\n",
    "movies_soup = getSoup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 50 movie titles\n",
      "Displaying 10 titles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/title/tt2382320/',\n",
       " '/title/tt9421570/',\n",
       " '/title/tt8110232/',\n",
       " '/title/tt7097896/',\n",
       " '/title/tt1160419/',\n",
       " '/title/tt6264654/',\n",
       " '/title/tt3480822/',\n",
       " '/title/tt9376612/',\n",
       " '/title/tt2379713/',\n",
       " '/title/tt0381061/']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_tags = movies_soup.find_all('a', attrs={'class': None})\n",
    "\n",
    "# filter the a-tags to get just the titles\n",
    "movie_tags = [tag.attrs['href'] for tag in movie_tags \n",
    "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
    "\n",
    "# remove duplicate links\n",
    "movie_tags = list(dict.fromkeys(movie_tags))\n",
    "\n",
    "print(\"There are a total of \" + str(len(movie_tags)) + \" movie titles\")\n",
    "print(\"Displaying 10 titles\")\n",
    "movie_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 50 movie user reviews\n",
      "Displaying 20 user reviews links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt2382320/reviews',\n",
       " 'https://www.imdb.com/title/tt9421570/reviews',\n",
       " 'https://www.imdb.com/title/tt8110232/reviews',\n",
       " 'https://www.imdb.com/title/tt7097896/reviews',\n",
       " 'https://www.imdb.com/title/tt1160419/reviews',\n",
       " 'https://www.imdb.com/title/tt6264654/reviews',\n",
       " 'https://www.imdb.com/title/tt3480822/reviews',\n",
       " 'https://www.imdb.com/title/tt9376612/reviews',\n",
       " 'https://www.imdb.com/title/tt2379713/reviews',\n",
       " 'https://www.imdb.com/title/tt0381061/reviews',\n",
       " 'https://www.imdb.com/title/tt10665338/reviews',\n",
       " 'https://www.imdb.com/title/tt3811906/reviews',\n",
       " 'https://www.imdb.com/title/tt9731534/reviews',\n",
       " 'https://www.imdb.com/title/tt1270797/reviews',\n",
       " 'https://www.imdb.com/title/tt1074638/reviews',\n",
       " 'https://www.imdb.com/title/tt10954652/reviews',\n",
       " 'https://www.imdb.com/title/tt6742252/reviews',\n",
       " 'https://www.imdb.com/title/tt0830515/reviews',\n",
       " 'https://www.imdb.com/title/tt6334354/reviews',\n",
       " 'https://www.imdb.com/title/tt3228774/reviews']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.imdb.com\"\n",
    "movie_links = [base_url + tag + 'reviews' for tag in movie_tags]\n",
    "print(\"There are a total of \" + str(len(movie_links)) + \" movie user reviews\")\n",
    "print(\"Displaying 20 user reviews links\")\n",
    "movie_links[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_soups = [getSoup(link) for link in movie_links]\n",
    "\n",
    "# get all 500 movie review links\n",
    "movie_review_list = [getReviews(movie_soup) for movie_soup in movie_soups]\n",
    "\n",
    "#movie_review_list = list(itertools.chain(*movie_review_list))\n",
    "#print(len(movie_review_list))\n",
    "\n",
    "#print(\"There are a total of \" + str(len(movie_review_list)) + \" individual movie reviews\")\n",
    "#print(\"Displaying 10 reviews\")\n",
    "#movie_review_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "There are a total of 250 individual movie reviews\n",
      "Displaying 10 reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/review/rw7427849/',\n",
       " 'https://www.imdb.com/review/rw7434303/',\n",
       " 'https://www.imdb.com/review/rw7423396/',\n",
       " 'https://www.imdb.com/review/rw7412934/',\n",
       " 'https://www.imdb.com/review/rw7434303/',\n",
       " 'https://www.imdb.com/review/rw7412553/',\n",
       " 'https://www.imdb.com/review/rw7410656/',\n",
       " 'https://www.imdb.com/review/rw7382705/',\n",
       " 'https://www.imdb.com/review/rw7441337/',\n",
       " 'https://www.imdb.com/review/rw7434888/']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movie_review_list = list(itertools.chain(*movie_review_list))\n",
    "print(len(movie_review_list))\n",
    "\n",
    "print(\"There are a total of \" + str(len(movie_review_list)) + \" individual movie reviews\")\n",
    "print(\"Displaying 10 reviews\")\n",
    "movie_review_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_texts = [getReviewText(url) for url in movie_review_list]\n",
    "\n",
    "# get movie name from the review link\n",
    "movie_titles = [getMovieTitle(url) for url in movie_review_list]\n",
    "\n",
    "# label each review with negative or positive\n",
    "\n",
    "# construct a dataframe\n",
    "df = pd.DataFrame({\n",
    "             'user_review': review_texts })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Time To Die (2021) :\\nMovie Review -When it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No Time to Die\" is an Action - Thriller movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first 20-25 minutes are superb (from the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not sure why others bashed No Time to Die ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ironically thrice postponed because of coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Before you spend (waste) anymore time here rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm so sick of all you negative pompous armcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30 minutes in and you realize that you do not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Before you spend (waste) anymore time here rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30 minutes in and you realize that you do not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What a total waste of movie resources that cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>THE MANY SAINTS OF NEWARK (2021) *** Alessandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Really? All that talent and money, and yet ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. . . THE MANY SAINTS OF NEWARK by saying with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When Dickie's father with his new Italian wife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Venom: Let there be Carnage (2021) is a movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Venom: Let there be Carnage (2021) is a movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I'm soooooooo tired of WOODY Harrelson in ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>So after watching the original Venom in 2018, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I absolutely loved this sequel, I wish that it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_review\n",
       "0   No Time To Die (2021) :\\nMovie Review -When it...\n",
       "1   \"No Time to Die\" is an Action - Thriller movie...\n",
       "2   The first 20-25 minutes are superb (from the m...\n",
       "3   I'm not sure why others bashed No Time to Die ...\n",
       "4   Ironically thrice postponed because of coronav...\n",
       "5   Before you spend (waste) anymore time here rea...\n",
       "6   I'm so sick of all you negative pompous armcha...\n",
       "7   30 minutes in and you realize that you do not ...\n",
       "8   Before you spend (waste) anymore time here rea...\n",
       "9   30 minutes in and you realize that you do not ...\n",
       "10  What a total waste of movie resources that cou...\n",
       "11  THE MANY SAINTS OF NEWARK (2021) *** Alessandr...\n",
       "12  Really? All that talent and money, and yet ove...\n",
       "13  . . . THE MANY SAINTS OF NEWARK by saying with...\n",
       "14  When Dickie's father with his new Italian wife...\n",
       "15  Venom: Let there be Carnage (2021) is a movie ...\n",
       "16  Venom: Let there be Carnage (2021) is a movie ...\n",
       "17  I'm soooooooo tired of WOODY Harrelson in ever...\n",
       "18  So after watching the original Venom in 2018, ...\n",
       "19  I absolutely loved this sequel, I wish that it..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20) #converting it into data frama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting only reviews to CSV & removing the index\n",
    "df.to_csv('data_scrapped/data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data_scrapped/data.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        rownumber = 0\n",
    "        for row in reader:\n",
    "             g=open(str(rownumber)+\".txt\",\"w\")\n",
    "             g.write(str(row))\n",
    "             rownumber = rownumber + 1\n",
    "             g.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23784c1f7cb08f751fc8275aaeeb793366452f178ab646d6f5c554e80b94c083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
